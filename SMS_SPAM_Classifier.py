# -*- coding: utf-8 -*-
"""Data_Mining_CA2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ACxSci5h5IwzAIbpQd9djAOT3jWDOerp
"""

#Importing Libraries
import pandas as pd
import numpy as np
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import StratifiedKFold
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC
from sklearn import metrics
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import GridSearchCV
from bs4 import BeautifulSoup
from sklearn.feature_extraction.text import CountVectorizer
import joblib

#Downloading necessary NLTK data
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt_tab')
nltk.download('punkt_tab')

#Data loading
df = pd.read_csv("SMSSpamCollection", sep='\t', header=None, names=["label", "message"])

#Displaying the first 5 rows
df.head()

#Preprocessing the data
def clean_text(text):
    """Clean and preprocess the text data"""
    #Removing HTML tags
    soup = BeautifulSoup(text, 'lxml')
    souped = soup.get_text()

    #Removing URLs, user mentions (@), and non-alphabetic characters
    souped = re.sub(r"(@|http://|https://|www)\S*", " ", souped)  # Remove URLs
    souped = re.sub(r"[^A-Za-z]+", " ", souped)  # Keep only alphabetic characters

    #Tokenizing and removing stopwords
    tokens = nltk.word_tokenize(souped)
    stop_words = set(stopwords.words('english'))
    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]

    #Lemmatizing words
    lemmatizer = WordNetLemmatizer()
    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]

    return " ".join(lemmatized_tokens)

#Cleaning the 'message' column in the dataset
df['cleaned_message'] = df['message'].apply(clean_text)

#Converting 'label' from categorical to numeric: ham = 0, spam = 1
df['label'] = df['label'].map({'ham': 0, 'spam': 1})


#Feature extraction using TF-IDF
#tfidf = TfidfVectorizer(max_df=0.95, min_df=0.05, ngram_range=(1, 2))
#X = tfidf.fit_transform(df['cleaned_message'])
#y = df['label']

# Feature extraction using CountVectorizer
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(df['cleaned_message'])
y = df['label']

#Cross-validation setup
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
smote = SMOTE(random_state=42)

#Initializing the models
nb_model = MultinomialNB()
svc_model = LinearSVC()

#Lists to store scores
nb_scores = []
svc_scores = []

#Cross-validation and evaluation
for train_index, test_index in kf.split(X, y):
    X_train, X_test = X[train_index], X[test_index]
    y_train, y_test = y[train_index], y[test_index]

#Applying SMOTE to balance the data
    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

    #Train and predict using Naive Bayes
    nb_model.fit(X_train_res, y_train_res)
    y_pred_nb = nb_model.predict(X_test)
    nb_scores.append(metrics.accuracy_score(y_test, y_pred_nb))

    #Train and predict using SVC
    svc_model.fit(X_train_res, y_train_res)
    y_pred_svc = svc_model.predict(X_test)
    svc_scores.append(metrics.accuracy_score(y_test, y_pred_svc))

from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

#Print detailed metrics for Naive Bayes
#Classification Report
print("Naive Bayes - Classification Report:")
print(metrics.classification_report(y_test, y_pred_nb))

#Confusion Matrix
#print("Naive Bayes - Confusion Matrix:")
#print(metrics.confusion_matrix(y_test, y_pred_nb))

cm = confusion_matrix(y_test, y_pred_nb)

plt.figure(figsize=(6,5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=['Not Spam', 'Spam'], yticklabels=['Not Spam', 'Spam'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

#Print detailed metrics for SVC
#Classification Report
print("SVC - Classification Report:")
print(metrics.classification_report(y_test, y_pred_svc))

#Confusion Matrix
#print("SVC - Confusion Matrix:")
#print(metrics.confusion_matrix(y_test, y_pred_svc))

cm1 = confusion_matrix(y_test, y_pred_svc)

plt.figure(figsize=(6,5))
sns.heatmap(cm1, annot=True, fmt="d", cmap="Blues", xticklabels=['Not Spam', 'Spam'], yticklabels=['Not Spam', 'Spam'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

#Saving models and TF-IDF vectorizer
joblib.dump(nb_model, 'nb_spam_classifier.pkl')
joblib.dump(svc_model, 'svc_spam_classifier.pkl')
#joblib.dump(tfidf, 'tfidf_vectorizer.pkl')

#Applying SMOTE for oversampling the minority class (spam)
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

#Hyperparameter Tuning for Naive Bayes using GridSearchCV
#Grid search for alpha parameter
param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0]}
grid_search = GridSearchCV(MultinomialNB(), param_grid=param_grid, cv=5, scoring='f1')
grid_search.fit(X_res, y_res)

best_nb_model = grid_search.best_estimator_

#Displaying best estimator
print(grid_search.best_estimator_)

nb_model=MultinomialNB(alpha=0.1)

#Evaluating the best Naive Bayes model on the test set
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.3, random_state=42)

y_pred_nb = best_nb_model.predict(X_test)

#Classification Report and Confusion Matrix for Naive Bayes
print("Naive Bayes - Classification Report:")
print(metrics.classification_report(y_test, y_pred_nb))

#print("Naive Bayes - Confusion Matrix:")
#print(metrics.confusion_matrix(y_test, y_pred_nb))

cm_nv = confusion_matrix(y_test, y_pred_nb)

plt.figure(figsize=(6,5))
sns.heatmap(cm_nv, annot=True, fmt="d", cmap="Blues", xticklabels=['Not Spam', 'Spam'], yticklabels=['Not Spam', 'Spam'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

#Applying SMOTE for oversampling the minority class (spam)
#Importing the SVC class
from sklearn.svm import SVC
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

#Hyperparameter Tuning for SVC using GridSearchCV
param_grid_svc = {
    'C': [0.1, 1, 10],
    'kernel': ['linear', 'rbf', 'poly']
}

grid_search_svc = GridSearchCV(SVC(), param_grid=param_grid_svc, cv=5, scoring='f1')
grid_search_svc.fit(X_res, y_res)

best_svc_model = grid_search_svc.best_estimator_

#Evaluating the best SVC model on the test set
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.3, random_state=42)

y_pred_svc = best_svc_model.predict(X_test)

#Classification Report and Confusion Matrix for SVC
print("SVC - Classification Report:")
print(metrics.classification_report(y_test, y_pred_svc))

#print("SVC - Confusion Matrix:")
#print(metrics.confusion_matrix(y_test, y_pred_svc))

cm_svc = confusion_matrix(y_test, y_pred_svc)

plt.figure(figsize=(6,5))
sns.heatmap(cm_svc, annot=True, fmt="d", cmap="Blues", xticklabels=['Not Spam', 'Spam'], yticklabels=['Not Spam', 'Spam'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

# Function to check if the message is ham or spam
def check_message(message):
    # Vectorize the input message using the same vectorizer
    message_vec = vectorizer.transform([message])

    # Assign your desired model to 'model' here
    # For example, if you want to use the Naive Bayes model:
    model = best_nb_model
    # if you want to use the SVC model:
    # model = best_svc_model

    # Predict the class using the trained model (0 = ham, 1 = spam)
    prediction = model.predict(message_vec)

    # Output the result
    if prediction == 1:
        return "This message is SPAM."
    else:
        return "This message is HAM."

# Example usage:
message = input("Enter the message to check: ")
result = check_message(message)
print(result)